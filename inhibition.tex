% -*- TeX-master: "ijcai18.tex" -*-

\section{Counterfactuals and inhibition}\label{sec:inhibition}

\subsection{Using counterfactual resimulation in practice}
\label{sec:practice}

Returning to our example, let's see how we can use counterfactual
resimulation to improve our understanding of the typical causal
narrative leading to phosphorylating a substrate. First, how may one
come to suspect that the narrative that is shown
Figure~\ref{fig:dumb-story} is incomplete \textit{a priori} ? And
then, how should one know what interventions might be worth trying in
order to discover some additional causal structure ?

There is no perfect answer here but there are definitely useful
heuristics we can use. In our example, one may notice by running
repeated simulations that when rule $p$ triggers, the kinase involved
is very likely to be phosphorylated (compared to the average ratio of
phosphorylated kinases). The fact that our current causal narrative
does not provide any explanation for this phenomenon is a sign that we
should investigate more to know whether this correlation is accidental
or revealing of a causal effect. In order to do so, it is natural to
intervene by blocking the last event phosphorylating the kinase
involved in $p$ in our sample traces. More generally, when
\begin{inparaenum}[(i)]
\item an event $e$ in a candidate causal narrative is executed
  unusually often in a context which is more specific than what is
  required by the left-hand side of the associated rule and
\item this effect cannot be explained by the action of other events in
  the same causal narrative,
\end{inparaenum}
then exploring counterfactual traces in which we block the last event
responsible for at least a part of the unexplained context in the
triggering a $e$ is likely to be worthwhile.

Back to our example, our simple heuristic suggests that we should
block the last event responsible for the phosphorylation of the kinase
before the substrate gets phosphorylated itself in sampled traces. On
the particular case of trace~(\ref{example-trace}) of
section~\ref{sec:example}, we ask: how likely is it that ``$p$ would
have happened had $pk$ not happened'' ?  This can be translated
literaly in the question of evaluating
$\mathbf{P}(\tau \models [\iota] \, \psi)$ where
\begin{inparaenum}[(i)]
  % \item $\tau$ is trace~(\ref{example-trace})
\item $\BLOCKED{\iota}{e'} = (e = pk)$ and
\item $\psi[\tau'] = (p \in \tau')$.\footnote{Here, by $p$ and $pk$,
    we refer to very specific events that appear at a particular time
    in $\tau$.}
\end{inparaenum}
This choice of $\iota$ and $\psi$ is a reasonable one most of the
time but some variations may be prefered occasionally. For example, if
the rule $pk$ for phosphorylating is very fast, blocking only a single
instance of the potential event associated with $pk$ may not have a
very large effect as a new instance may trigger almost immediately
after in most counterfactual traces, cancelling the effect of the
intervention.  In this case, it is useful to make $\iota$ block every
instance of the potential event associated with $pk$ in a defined
timeframe.
