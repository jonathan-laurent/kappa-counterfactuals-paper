% -*- TeX-master: "ijcai18.tex" -*-

\section{Evaluating counterfactual statements}\label{sec:counterfactual}

%\subsection{On the nature of  counterfactual statements}

Let's suppose that we have observed a trace $\tau$ in which a kinase
$k$ gets phosphorylated ($pk$) at time $t$ and then binds ($b$) to a
substrate $s$, which gets phosphorylated in turn ($p$). One may wonder
what causal influence event $pk$ had on event $p$ in this specific
scenario. According to a counterfactual account of causality, this
translates into the question of how likely it is that {``$p$ would
  have happened had $pk$ not happened''}.\footnote{We are being
  oversimple here for ease of exposition. In reality, how to best
  express such a statement of actual causality in terms of
  counterfactuals is still a matter of endless debate
  \cite{halpern2016actual}. }

A naive attempt to answer this question may go as follows: one may
sample many simulation traces starting from the state of $\tau$ one
moment before time $t$ and reject every trace in which rule $pk$
triggers on $k$ in some time window around $t$.  Among the remaining
traces, we would measure the frequency of those for which $s$ gets
phosphorylated by $k$ in some defined time frame and take it as an
estimate of the likelihood of our counterfactual statement.

The line of reasoning above is flawed in two major ways. First, $k$
and $s$ may never bind to each other in the first place in most of the
sampled traces,\footnote{For example, this would be the case if $s$
  was competing with many other substrates for binding to $k$.} in
which case whether or not $k$ got phosphorylated is irrelevant. Worst,
the consequent of the more precise counterfactual statement
\textit{``had $pk$ not happened, the opportunity for $p$ would have
  been cut short by an early unbinding event between $k$ and $s$''}
would not even make sense on those traces.
%One may suggest to make the same sampling experiment, this time also
%conditioning by $k$ binding to $s$. However, it is unclear how many
%other such things we may have to condition by.
The key lesson here is that counterfactual statements are undetachable
from the context in which they are formulated (in our example the
trace $\tau$). Quoting Lewis, they refer to worlds ``\textbf{closest}
to the actual one in which something went different''
\cite{lewis1974causation}. In our example, all those closest worlds
must feature $s$ and $k$ binding together as they do in $\tau$,
among other things.

The second problem comes from a more fundamental impossibility of
evaluating counterfactual statements through observation alone. As a
way to illustrate this, let's imagine that every kinase has a second
phosphorylation site $x$, which state has no impact on the kinase
behavior but is almost perfectly correlated with the state of the
first phosphorylation site (which determines how strongly the kinase
can bind to a substrate). Then, conditioned on $k$ getting
phosphorylated at $x$, it is indeed much more likely that the first
substrate it binds to will get phosphorylated in turn. However, we
would not say that these two events are counterfactually dependent (or
even causally related). The key lesson here is that causality and
counterfactuals are not about conditioning but about
\emph{interventions}. This is a fundamental idea in modern causal
inference, which is well illustrated by a famous example: observing
repeatedly that your pavement gets wet whenever it rains gives you no
information about whether you live in a universe in which rain causes
wet pavements or in which wet pavements cause rain. In order to find
out, you need to intervene and spill water on your pavement yourself
to see whether or not it starts raining as a result.

Pearl's standard account of counterfactual statements is based on
applying \textit{``surgical interventions''} on structural equation
models. Such a model features a finite sequence $(x_1, \dots, x_n)$ of
variables. Each variable $x_i$ is associated a \emph{functional
  equation} of the form $x_i = f_i(x_1, \dots, x_{i-1}, u_i)$, where
$f_i$ is a deterministic function and $u_i$ is a random
variable. Ideally, each $f_i$ defines an independent and autonomous
physical mechanism. This is partially enforced by the requirement that
the $(u_i)_i$ must be mutually independent (Markovian
hypothesis). Then, given some observation $e$, the probability of the
counterfactual statement ``had $x_j$ been equal to $a$, $\psi$ would
have been be true'' can be evaluated following a three-steps process:
\begin{inparaenum}[]
\item (\textbf{abduction}) compute the distribution $p_e$ of possible values for
  $\vec u$ given observation $e$, then
\item (\textbf{action}) intervene in the model by replacing the
  defining equation for $x_j$ by ``$x_j = a$'' and finally
\item (\textbf{prediction}) compute the probability that $\psi$ is true in this
  new model when $\vec{u}$ is distributed along $p_e$.
\end{inparaenum}
Because rule-based models do not have a natural encoding in term of
structural equations, Pearl's construction does not apply
straightforwardly in our case. The semantics we propose is
very close in spirit though.



\subsection{A semantics for counterfactuals}




We start by formalizing the notion of an intervention. An intervention
$\iota$ (``blocking $pk$" in our example) is a predicate
$\BLOCKED{\iota}{e}$ that determines whether or not event $e$ is
blocked. Given a predicate $\psi$ over traces, we write
the proposition \textit{``Had intervention $\iota$ happened in trace
  $\tau$, $\psi$ would have been true with probability greater than
  $p \in [0,1]$''} as:
\[ \tau \models_p [\iota] \, \psi.
\]

To give an operational meaning to this statement, we invoke the
continuous time Markov chain (CTMC) semantics of a Kappa model as
defined and implemented in
\cite{DanosEtAl-APLAS07,BoutillierEK17}. For the present purpose it is
conceptually useful to think of a CTMC abstractly in terms of the
random repeated realization of abstract event. For every possible
abstract event, we imagine a bell that rings at a time $t$ drawn from
an exponential distribution $\lambda_r\exp(-\lambda_r t)$, where
$\lambda_r$ is the stochastic rate constant of $r$. A simulation trace
can be viewed as the realization of a random variable $T$ determined
by the set $\omega$ of ring times: Starting with an initial mixture,
when a bell rings at $t$, its associated potential event $(r, \xi)$
transforms the mixture according to $r$ if $\xi$ yields a valid
embedding of the left hand side of $r$ in the current mixture and time
advances by $t$. Otherwise, time advances and nothing happens---a null
event. Repeat on the resulting mixture.

We can extend this viewpoint to include interventions. For an
intervention $\iota$, we define the random variable $\ATRAJ{}$ much in
the same way as $T$, except that each time the bell rings, we require
$\BLOCKED{\iota}{e, t}$ to be false for the potential event
$e=(r, \xi)$ to be considered.  Counterfactual traces that are closest
to the actual trace $\tau$ are then sampled by generating realizations
of $\ATRAJ{}$ that inherit, whenever possible, the subset of $\omega$
that made up $\tau$. 
% An efficient implementation of this specification
% for sampling the conditional random variable $\CTRAJ{}$ is available at
% \begin{center}
%   \url{https://github.com/jonathan-laurent/kappa-counterfactuals}.
% \end{center} 
We refer to this natural extension of CTMC semantics as
\textit{counterfactual re-simulation} or \textit{co-simulation} for
short. Using co-simulation, we can operationalize the counterfactual
statements as follows.

\begin{definition}[Semantics of counterfactual statements] We write
  $\tau \models_p [\iota] \, \psi$ the counterfactual statement
  \textit{``had intervention $\iota$ happened in trace $\tau$,
    predicate $\psi$ would have been true with probability greater
    than $p$''}.  It is defined as follows:
  \[ \tau \models_p [\iota] \, \psi \quad \Longleftrightarrow \quad
    \mathbf{P}( \psi(\ATRAJ{}) \ |\ T = \tau) \,\geq\, p \]
\end{definition}

\subsection{The counterfactual resimulation algorithm}

Counterfactual traces can be sampled using the algorithm described in
Listing~\ref{alg:cosimulation}.

\input{algos/cosimulation}
\input{proofs/cosimulation}