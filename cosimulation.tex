% -*- TeX-master: "ijcai18.tex" -*-

\newcommand{\PCFST}[0]{\ProbParen{\CFST{}}}

\newcommand{\ItAbduction}[0]{(\textit{abduction})}
\newcommand{\ItAction}[0]{(\textit{action})}
\newcommand{\ItPrediction}[0]{(\textit{prediction})}


\section{Evaluating counterfactual
  statements}\label{sec:counterfactual}


In the context of our toy model, the counterfactual statement we must
assess is: ``If $pk$ had not happened, $p$ would not have happened."
Our account in the previous section suggests that $pk$ played a role,
but it is also clear that given the stochastic nature of rule firing
$p$ could well have happened even in the absence of $pk$; it just is
unlikely. Counterfactual statements are not either true or false, but
have degrees of likelihood. To assess that likelihood is our task.

Given an original (factual) trace $\tau$, a naive approach might be
to sample counterfactual traces, each of which starts with the
state of the system attained in $\tau$ just before event $pk$
happened, but in which we skip over $pk$ and then run an unconstrained
simulation from that point onward. In this approach traces would
quickly diverge from the original, distorting the causal role that
$pk$ played \emph{specifically} in it. The question here is not what
causal role $pk$ \emph{can} play in principle, but what role it
actually \emph{did} play in $\tau$.


Pearl's standard account of counterfactual statements is based on
applying \textit{``surgical interventions''} on structural equation
models. Such a model features a finite sequence $(x_1, \dots, x_n)$ of
variables. Each variable $x_i$ is associated a \emph{functional
  equation} of the form $x_i = f_i(x_1, \dots, x_{i-1}, u_i)$, where
$f_i$ is a deterministic function and $u_i$ is a random
variable. Ideally, each $f_i$ defines an independent and autonomous
physical mechanism. This is partially enforced by the requirement that
the $(u_i)_i$ must be mutually independent (Markovian
hypothesis). Then, given some observation $e$, the probability of the
counterfactual statement ``had $x_j$ been equal to $a$, $\psi$ would
have been be true'' can be evaluated following a three-steps process:
\begin{inparaenum}[]
\item \ItAbduction{} compute the distribution $p_e$ of possible values
  for $\vec u$ given observation $e$, then
\item \ItAction{} intervene in the model by replacing the defining
  equation for $x_j$ by ``$x_j = a$'' and finally
\item \ItPrediction{} compute the probability that $\psi$ is true in
  this new model when $\vec{u}$ is distributed along $p_e$.
\end{inparaenum}
Because rule-based models do not have a natural encoding in term of
structural equations, Pearl's construction does not apply
straightforwardly in our case. Our proposal is very close in spirit
though.



\subsection{A semantics for counterfactuals}
\label{subsec:counterfactuals-semantics}

An intervention $\iota$ prevents the occurrence of selected events. It
is defined by a predicate $\BLOCKED{\iota}{\cdot}$ ranging over
events. (Our framework can accomodate a much broader range of
interventions, but we make this restriction for ease of exposition.)
Given a predicate $\psi$ over traces, we write the statement
\textit{``Had intervention $\iota$ happened in trace $\tau$, $\psi$
  would have been true''} as $\CFST{}$.

To assign a probability to this statement, it is conceptually useful
to think of the CTMC induced by a model in terms of the repeated
random realization of potential events.  For every possible potential
event $(r, \xi)$, one has to imagine a bell that rings randomly
according to a Poisson process of parameter $\lambda_r$.\footnote{In
  other words, the time intervals between consecutive ringings are
  drawn from exponential distributions of parameter $\lambda_r$.}  A
simulation trace can be viewed as a deterministic function $T$ of the
random variable $\Sigma$ that features the set of ring times for every
potential event (we call it \emph{schedule} and it corresponds to
$\vec{u}$ in Pearl's construction): starting with the initial mixture
and advancing in time, every time a bell rings, its associated
potential event $e$ transforms the current mixture $m$ if
$\TRIGGERABLE{m}{e}$. For example, if the bell labeled \textit{``apply
  rule $b$ on substrate $3$ and kinase $4$''} rings on the mixture of
Figure~\ref{fig:mixture}, then a bond is created between these two
agents. However, if the bell labeled \textit{``apply rule $b$ on
  substrate $1$ and kinase $2$'}' rings on the same mixture, nothing
happens.

We can extend this viewpoint to include interventions. For an
intervention $\iota$, we define the altered trace $\ATRAJ{}$ much in
the same way as $T$, except that each time the bell associated to $e$
rings at time $t$, we also require $\BLOCKED{\iota}{(e, t)}$ to be
false for $e$ to trigger. Then, given an observed trace $\tau$, an
intervention $\iota$ and a predicate $\psi$, we compute $\PCFST{}$
according to Pearl's three-steps procedure: \ItAbduction{} we
condition the distribution of $\Sigma$ on the observation that
$T=\tau$, then \ItAction{} we alter the behavior of simulation with
intervention $\iota$ and \ItPrediction{} we compute the probability of
$\psi$ in the resulting setting. This results in the following
definition.

\begin{definition}[Semantics of counterfactual statements]\label{def:counterfactuals}
  For $\tau$ an observed trace, $\iota$ an intervention and $\psi$ a
  predicate on traces, the probability of the counterfactual statement
  \textit{``had intervention $\iota$ happened in trace $\tau$,
    predicate $\psi$ would have been true''} is defined as:
  \[ \PCFST{} \eqdef \ \ProbParen{\psi(\ATRAJ{}) \ |\ T = \tau}. \]
\end{definition}

\subsection{The counterfactual resimulation algorithm}
\label{subsec:cosim-algo}

Following Definition~\ref{def:counterfactuals}, we can estimate the
probability of the counterfactual statement
$\CFST{}$ by sampling instances of the random
variable $\CTRAJ{}$. Such instances are called \emph{counterfactual
  traces}. Intuitively, they give an account of what else trace $\tau$
could have been had intervention $\iota$ happened.  We introduce
Algorithm~\ref{alg:cosimulation} a variation of Doob-Gillespie's
algorithm to sample a counterfactual trace efficiently given a
reference trace $\tau$ and an intervention $\iota$.  We call it
\emph{counterfactual resimulation} algorithm, since it works by going
through every event of $\tau$, resimulating only those parts of $\tau$
that are remotely affected by $\iota$. In particular, when $\iota$ is
the trivial intervention ($\BLOCKED{\iota}{\cdot} = \text{false}$), it
outputs $\tau$ with no modification.





This algorithm relies on a modified notion of activity we call
\emph{divergent activity}. We define the set of \emph{divergent
  embeddings} of the left-hand side of a rule $r$ into mixture $m$
and relative to $m_0$ as
\[\DEMBS{r}{m, m_0} \eqdef \EMBS{r}{m} \setminus \EMBS{r}{m_0}.\]
Equivalently, a divergent embedding is an embedding whose codomain
features a \emph{divergent site}, that is, a site whose state differs
across $m$ and $m_0$. The {divergent activity} of a rule $r$ in
mixture $m$ relative to $m_0$ is then defined as the product
$\lambda_r|\DEMBS{r}{m, m_0}|$. The \emph{total divergent activity} of
the system, $\alpha'(m, m_0)$, is the sum of all divergent
activities. Finally, we use the notation $\TSTATE{t}{\tau}$ to refer
to the mixture at time $t$, which obtains from the initial mixture
after updating it for each event in turn up to time $t$ in $\tau$.

\input{algos/cosimulation}

The role and relevance of the concept of divergent activity in the
counterfactual resimulation algorithm can be summarized by the
following theorem, where we write $\tau \cap I = \emptyset$ as a
shortcut for the proposition ``no event of trace $\tau$ triggers in
the time interval $I$''.
\begin{theorem}[Property of the divergent activity]\label{thm:div-activity}
  Let $\tau$ a trace
  and $\iota$ an intervention. Let $I = (t, t+\delta)$ a time interval
  such that $\tau \cap I = \emptyset$ and $m_0 =
  \TSTATE{t}{\tau}$. Then, we have
  \[\CProb{ \ATRAJ{} \cap I = \emptyset }{ T=\tau,\
      \TSTATE{t}{\ATRAJ{}} = m\ }
    \ =\ e^{-\alpha'(m, m_0) \cdot \delta}.
  \]
\end{theorem}
\noindent Indeed, at every iteration of
Algorithm~\ref{alg:cosimulation}, the divergent activity $\alpha'$
determines the probability that a ``counterfactual event'' triggers
before the time of the next event in $\tau$ (test of line
\ref{cosim:cev}).  A proof of Theorem~\ref{thm:div-activity} is
available Appendix~\ref{ap:div-activity}.




\subsection{Using counterfactual resimulation in practice}
\label{subsec:cosim-practice}

Returning to our example, let's see how we can use counterfactual
resimulation to improve our understanding of the typical causal
narrative leading to the phosphorylation of a substrate. First, how
may one come to suspect that the narrative that is shown
Figure~\ref{fig:dumb-story} is incomplete \textit{a priori} ? And
then, how should one know what interventions might be worth trying in
order to discover some additional causal structure through
counterfactual resimulation?

There is no perfect answer here but there are heuristics we can
use. In our example, one may notice by running repeated simulations
that when rule $p$ triggers, the kinase involved is very likely to be
phosphorylated. The fact that the causal narrative
Figure~\ref{fig:dumb-story} does not provide any insight into this
phenomenon is a sign that we should investigate whether it is
an accidental correlation or revealing of an unknown causal effect. In
order to do so, it is natural to intervene by blocking the last event
phosphorylating the kinase involved in $p$ in sampled traces. More
generally, when
\begin{inparaenum}[(i)]
\item an event $e$ in a candidate causal narrative is executed
  unusually often in a context which is more specific than what is
  required by the left-hand side of the associated rule and
\item this effect cannot be explained by the action of other events in
  the same causal narrative,
\end{inparaenum}
\textit{then} exploring counterfactual traces in which we block the last event
responsible for at least a part of the unexplained context in the
triggering a $e$ is likely to be worthwhile.

In our example, this heuristic suggests that we should block the last
event responsible for the phosphorylation of the kinase before the
substrate gets phosphorylated itself in sampled traces. For the
particular case of trace~(\ref{example-trace}) of
section~\ref{sec:example}, we ask: how likely is it that ``$p$ would
have happened had $pk$ not happened'' ?  This can be translated
literaly in the question of evaluating $\mathbf{P}(\CFST{})$ where
\begin{inparaenum}[(i)]
  % \item $\tau$ is trace~(\ref{example-trace})
\item $\BLOCKED{\iota}{e'} = (e = pk)$ and
\item $\psi[\tau'] = (p \in \tau')$.\footnote{Here, by $p$ and $pk$,
    we refer to very specific events that appear at a particular time
    in $\tau$.}
\end{inparaenum}
This choice of $\iota$ and $\psi$ is reasonable most of the
time but some variations may be prefered occasionally. For example, if
the rule $pk$ for phosphorylating is very fast, blocking only a single
instance of the potential event associated with $pk$ may not have a
very large effect as a new instance would trigger almost immediately
after in most counterfactual traces, cancelling the effect of the
intervention.  In this case, it is useful to make $\iota$ block every
instance of the potential event associated with $pk$ in a defined
timeframe.

Sampling counterfactual traces repeatedly for
trace~(\ref{example-trace}) would reveal that ``event $p$ would not
have happened had $pk$ not happened'' with very high probability.
However, we can go further by using counterfactual traces to
\textit{explain} this influence using both activation and inhibition
arrows (Figure~\ref{fig:cex}).