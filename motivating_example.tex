\section{Motivating example}\label{sec:example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BACKGROUND ON KAPPA
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Some background on Kappa}

Stochastic simulations of Kappa models can be run using the Gillespie
algorithm, which is summarized Listing~\ref{alg:gillespie}.

\input{algos/gillespie}

In Gillespie's algorithm, the activity of a rule $r$ is defined as the
product $\lambda_r|\EMBS{r}{M}|$ of its reaction rate by the number of
embeddings of its left hand side in the current reaction mixture.
Then, simulating a trace works by repeating the following steps:
\begin{inparaenum}[1)]

\item draw the time before the next simulation event from an
  exponential distribution of parameter the total activity $\alpha$ of
  the rules and increment the current time by this amount
\item draw a rule $r$ with probability proportional to its activity
\item pick an instance of the left hand side of $r$ uniformly in the
  current mixture and rewrite it.
\end{inparaenum}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% TRADITIONAL PATHWAY ANALYSIS FALLS SHORT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Where traditional pathway analysis falls short}

% Much more to say about Kappa

We illustrate the need for counterfactual reasoning on a toy example
in Kappa. Consider a model with two types of agents, kinases $K$ and
substrates $S$, interacting according to the rules depicted in
Figure~\ref{fig:model}.

\input{figures/model}

For the sake of simplicity, consider an initial mixture $I$ with only
a single kinase and a single substrate whose sites are free and
unphosphorylated. We then ask: Starting from $I$, \textbf{how} is $p$
triggered ? We are not merely looking for an account of reachability
but rather for causal narratives, that is, collections of necessary
events connected by causal influences.

A stochastic simulation \cite{DanosEtAl-APLAS07} might produce the
following trace (events are labelled by the rules that induced them):
\begin{align}\label{example-trace} b,\ \ u,\ \ pk,\ \ b,\ \ p,\ \
  u^{*},\ \ \cdots
\end{align} Figure~\ref{fig:dumb-story} depicts the causal narrative
explaining the occurrence of $p$ according to existing techniques
\cite{DBLP:conf/fsttcs/DanosFFHH12,DanosEtAl-CONCUR07}. The arrow
between $b$ and $p$ is called an \textit{activation arrow}, meaning
that $b$ modifies an aspect of state (by creating a link) that enables
$p$ to happen.

\input{figures/dumb-story}

This narrative, however, is blind to the critical role of $pk$ in the
original trace. Looking at the rules in Figure~\ref{fig:model} one
notes that:
\begin{inparaenum}[(i)]
\item the phosphorylation rule $p$ is slow
\item the average time $K$ and $S$ remain bound depends on whether $K$
  is phosphorylated, as manifest in the two unbinding rules $u$ (fast,
  if $K$ is not phosphorylated) and $u^{*}$ (slow, if $K$ is
  phosphorylated).
\end{inparaenum} It seems reasonable to assert that $p$ would probably
not have happened had $pk$ not happened, as the opportunity for $p$
would have been cut short by a fast unbinding event. We therefore
argue that $pk$, although it does not activate $b$ or $p$ directly,
should be part of a causal narrative for $p$. Reasoning of this kind
is \textit{counterfactual} and can be deployed to define causality
\cite{lewis1974causation,lewis2000causation}.

In section~\ref{sec:counterfactual}, we give a rigorous semantics to
this line of reasoning. In section~\ref{sec:inhibition} we show that
counterfactual statements can be expressed using inhibition arrows,
leading to the explanation shown in Figure~\ref{fig:cex}.

% Therefore, although the causal relevance of $pk$ cannot be justified
by activation arrows, it is supported by a counterfactual statement.
% In the rest of this abstract, we %give a formal semantics to
counterfactual statements and investigate how %they can be used %to
produce more satisfying causal explanations.