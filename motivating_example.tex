% -*- TeX-master: "ijcai18.tex" -*-

\section{Motivating example}\label{sec:example}

In this section, we provide some background on the Kappa language and
introduce a toy example motivating the need for counterfactual
reasoning in analyzing the causal structure of simulation traces.

% Maybe we should say a few eords here about what the model is about
% so that the reader is not shocked by the use of the word
% phosphorylation"

\subsection{Some background on Kappa}\label{sec:background}

Proteins are complex molecular machines that interact with one another
to establish a kind of operating system that determines what a cell
should do based on a variety of internal and external chemical and
physical inputs. These interactions consist in, roughly, tagging and
un-tagging each other with molecular flags and binding and un-binding
each other to form transient associations. In this way, proteins come
to have ``state" that can control the interactions they engage
in. Each kind of protein is usually present in several copies, that
is, proteins have an abundance.
 
In Kappa, a protein is modeled as an abstract \emph{agent} with a name
that designates its \emph{type} and a signature of distinguishable
\emph{sites} at which it can be tagged or bound by other agents. A
site can bind at most one agent at a time and must be in a definite
state.
% , each type of agent being described in the model's
% \emph{signature}.

In our illustrative toy example, we consider two types of agents for
which we use biological nomenclature. One type, $S$, is a substrate
that receives a tag known as a phosphate group in a phosphorylation
interaction. The other, $K$, is a kinase that phosphorylates
$S$. Agents of both types feature a binding site at which they can
bind one another and a site that can be in one of two possible states:
\emph{unphosphorylated} or \emph{phosphorylated}. Thus, agents of type
$K$ also have a phosphorylation state, but for the sake of simplicity
we will have them acquire it ``spontaneously", as specified below.

A \emph{mixture} is a multiset of agents whose state at each site is
fully specified. A mixture represents the state of a system and can be
thought of as a (potentially large) graph consisting of many connected
components. In a mixture, agents of the same type are distinguished by
a unique global identifier.

\input{figures/mixture}

As indicated in the Introduction, interactions between agents are
modeled by local rewriting \emph{rules}.  A rule $r$ is defined by a
triple $(\RLHS{r}, \RRHS{r}, \lambda_r)$, where $\RLHS{r}$ is the
left-hand side specifying a pattern (the pre-condition), $\RRHS{r}$
the right-hand side (or post-condition) and $\lambda_r$ a firing rate.
The basic idea is that a ``location" at which $\RLHS{r}$ matches the
mixture is rewritten in place by $\RRHS{r}$, thereby changing the
state of the system. (Technically, a rule also requires a mapping from
agents in $\RLHS{r}$ to agents in $\RRHS{r}$ to make the rewrite
unambiguous.) By virtue of the $\lambda_r$, the rules of a model,
together with an initial number of agents, constitute a dynamical
system, to be defined shortly.

Agents in our toy model are subject to the rules depicted in
Figure~\ref{fig:model}. Rule $b$ states that kinases and substrates
can bind each other provided their binding sites are free
(unbound). Note that $\RLHS{b}$ of rule $b$ is a pattern: It omits
mentioning the sites that carry phosphorylation state, which are
therefore not considered when matching $\RLHS{b}$ to the
mixture. Rules $u$ and $u^{*}$ define unbinding events that depend on
the phosphorylation state of the kinase $K$. The distinction is
motivated by kinetics: Rule $u$ fires at a faster rate than $u^{*}$.
Rule $p$ specifies that a substrate can be phosphorylated when it is
bound to a kinase. For the sake of simplicity, we model the
phosphorylation of a kinase as a spontaneous process (rule $pk$).

\input{figures/model}

In defining dynamics, we take a slightly circuitous route, which will
prove useful in section~\ref{sec:counterfactual}. A \emph{potential
  event}, is a pair $(r, \xi)$ where $r$ is a rule and $\xi$ a mapping
from agents in $\RLHS{r}$ to global identifiers. We say that
$(r, \xi)$ is \emph{executable} in mixture $m$ if the global
identifiers assigned by $\xi$ exist in $m$ and the agents bearing them
match $\RLHS{r}$. In this case, we write $\TRIGGERABLE{m}{(r, \xi)}$
(read ``$m$ admits $(r, \xi)$") and $\xi$ is called an
\emph{embedding} of $\RLHS{r}$ into $m$:
\[\EMBS{r}{m} \eqdef \{ \xi \,:\, \TRIGGERABLE{m}{(r, \xi)}\}.\]
Whenever $m \vdash (r, \xi)$, we write $m'=\UPDATE{m}{(r, \xi)}$ for
the mixture $m'$ obtained by executing $(r, \xi)$, i.e.\@ by rewriting
the agents with identifiers in the codomain of $\xi$ into $\RRHS{r}$.

The \emph{activity} $\alpha_r(m)$ of a rule $r$ in a given mixture $m$,
is defined by the product of the rule propensity and the number of
embeddings of $\RLHS{r}$ into $m$:
$\alpha_r(m)=\lambda_r|\EMBS{r}{m}|$. For example, in
Figure~\ref{fig:mixture}, rule $b$ has activity $2\lambda_b$ and rule
$u$ has activity $0$. The \emph{total activity} of a mixture is given
by $\alpha(m)=\sum_r\alpha_r(m)=\sum_r\lambda_r|\EMBS{r}{m}|$.

The continuous-time Markov chain associated with a model can be
simulated with the \emph{Doob-Gillespie (DG) algorithm}
\cite{gillespie1977exact}, which loops over the
following steps:
\begin{inparaenum}[(1)]
\item draw a time interval $\delta$ to the next event from an
  exponential distribution with parameter $\alpha(m)$ and increment
  the simulated system time by $\delta$,
\item draw a rule $r$ with probability $\alpha_r(m)/\alpha(m)$ and
\item pick uniformly an embedding $\xi$ of $r$ in $m$ and execute the
  potential event $(r, \xi)$.
\end{inparaenum}
This algorithm has a sophisticated implementation tuned for rule-based
models in Kappa as described in
\cite{DanosEtAl-APLAS07,BoutillierEK17}; it is available at
kappalanguage.org. The algorithm outputs a sequence of (realized)
\emph{events}, called a \emph{trace}, where an event is formally
defined as a pair $(e, t)$ with $e$ a potential event and $t$ its time
of occurrence.

\input{algos/gillespie}

\subsection{Where existing analysis falls short}
\label{subsec:dumb-story}

% What about asking the question for the specific trace to make it
% clearer we are talking about actual causality ?

Consider the toy model of Figure~\ref{fig:model} and assume, for the
sake of illustration, an initial mixture $I$ with only a single kinase
and a single substrate whose sites are unbound and
unphosphorylated. We then ask: Starting from $I$, \emph{how} is $p$
typically achieved? We are not merely looking for an account of
reachability but for a causal explanation, i.e.\@ a collection of
necessary events connected by causal influences.

For example, a stochastic simulation might produce the following trace
(whose events are labelled by the rules that induced them):
\begin{align}
  \label{example-trace} b,\ \ u,\ \ pk,\ \ b,\ \ p,\ \
  u^{*},\ \ \cdots
\end{align} 
Current
techniques \cite{DBLP:conf/fsttcs/DanosFFHH12,DanosEtAl-CONCUR07}
generate a causal account by first computing a \emph{sub-trace} of
(\ref{example-trace}) that is
\begin{inparaenum}[(i)]
\item \emph{valid} in the sense that each of its events can be
  triggered in turn starting from the initial mixture and
\item \emph{minimal} in the sense that none of its valid sub-traces
  features $p$.
\end{inparaenum}
Relations of enablement among the events in the minimal sub-trace are
then determined to yield a directed acyclic graph. Minimization is, in
general, an NP-hard problem, although trivial in our toy
example. Figure~\ref{fig:dumb-story} depicts the explanation graph for
the occurrence of $p$. Note that, in the original trace, the first
occurence of $b$ sets the necessary conditions for $p$, but these are
subsequently undone by $u$ only for the second occurrence of $b$ to
re-introduce them. This illustrates why minimization compresses a
trace into events that are necessary for the outcome---which includes
eliminating futile cycles. Thus, the explanation graph simply consists
in moving from the initial condition $I$, symbolized by the
\emph{init} event, to the last $b$ before the $u$. The arrows are
enablement relations as defined informally in the Introduction (see
also section~\ref{sec:inhibition}).

\input{figures/dumb-story}

The problem is that the explanation depicted in
Figure~\ref{fig:dumb-story} fails to recognize the critical role of
$pk$ in the original trace. Given the rules of the model, one notes
that $p$ is slow and the average time that $K$ remains bound to $S$
depends on the phosphorylation state of $K$. The kinase $K$ is
phosphorylated in event $pk$, causing the complex between $K$ and $S$
to be sticky and giving the slow phosphorylation $p$ a chance to
occur. It seems reasonable to assert that $p$ would probably not have
happened had $pk$ not happened, since the opportunity for $p$ would
have been curtailed by a fast unbinding event. Thus, $pk$ should be
part of the explanation, although it neither enables $b$ nor $p$
directly (both rules are independent of $K$'s phosphorylation
state). Reasoning of this kind is \emph{counterfactual} and can be
deployed to define causality
\cite{lewis1974causation,pearl2009causality}.

In section~\ref{sec:counterfactual}, we give a rigorous semantics to
this line of reasoning and introduce an algorithm for simulating
counterfactual scenarios. In section~\ref{sec:inhibition}, we show how
counterfactual dependencies between events can be systematically
explained in terms of a combination of enablement and prevention
arrows, leading to the explanation shown Figure~\ref{fig:cex}. 
%for the counterfactual dependency between $p$ and $pk$ in our example.
