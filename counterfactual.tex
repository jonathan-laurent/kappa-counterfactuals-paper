\section{Counterfactual simulation}

In this section, we derive a variation of the Gillespie algorithm
for simulating counterfactual traces. That is, given a
reference trace $\tau$ and an intervention $\iota$, we show how to
simulate an instance of $\CTRAJ{}$. Before we proceed, 
it is useful to refresh our memory about
the original Gillespie algorithm, which is summarized in 
Listing~\ref{alg:gillespie}.


In Gillespie's algorithm, the activity of a rule $r$ is defined as
the product $\lambda_r|\EMBS{r}{M}|$ of its reaction rate by the number
of embeddings of its left hand side in the current reaction mixture.
Then, simulating a trace works by repeating the following steps:
\begin{inparaenum}[1)]
\item draw the time before the next simulation event from an exponential
distribution of parameter the total activity $\alpha$ of the rules and
increment the current time by this amount
\item draw a rule $r$ with probability proportional to its activity
\item pick an instance of the left hand side of $r$ uniformly in
the current mixture and rewrite it.
\end{inparaenum}
A key property of Kappa's CTMC semantics that can be used to establish 
the corectness of this algorithm is the following.
%
%
\begin{proposition}\label{prop:gillespie}
Let $I=[t,\; t+\delta]$ a time interval and $m$ a mixture. Then,
\[ \CProb{ T \cap I = \emptyset }{ \TSTATE{t}{T} = m } 
   = e^{-\alpha(m) \cdot \delta} \]
where $\alpha(m)$ is the total activity of mixture $m$.
\end{proposition}
%
%
%\input{proofs/gillespie-pty}
A similar theorem can be proved for counterfactual traces, involving
a modified notion of activity we call \emph{divergent activity}.
Indeed, suppose we are simulating a counterfactual trace and the current
mixture at time $t$ is $m$. Let $m_0$ the state of the reference trace
at time $t$. We say that a site is divergent if it has
different states in $m$ and $m_0$.
Besides, an embedding of the left hand side of a rule $r$ into $m$
that features at least one divergent site is said to be divergent. We write
$\DEMBS{r}{m, m_0}$ the set of all such embeddings.
Finally, we define the divergent
activity of a rule as the product of its rate by the number of divergent
embeddings of its left hand side into $m$ and write $\alpha'(m, m_0)$
the total divergent activity:
\[\alpha'(m, m_0) = \sum_r \lambda_r |\DEMBS{r}{m, m_0}|. \] 
Then, we can state the counterpart of Proposition~\ref{prop:gillespie}
for counterfactual simulation.
\begin{proposition}\label{prop:cosim-waiting}
Let $\tau$ a trace and $\iota$ an intervention. 
Let $I$ a time interval of width $\delta$ such that 
$\tau \cap I = \emptyset$. Then,
\[
  \CProb{ \hat T_\iota \cap I = \emptyset }
        { T=\tau,\ \TSTATE{t}{\hat T_\iota} = m\ }
  \,=\ e^{-\alpha'(m, m_0) \cdot \delta}
\]
where $m_0 = \TSTATE{t}{T}$ and $\alpha'(m, m_0)$ is the divergent
activity of $m$ in respect to $m_0$.
\end{proposition}

%As summarized on Listing~\ref{alg:gillespie}, simulating a trace using 
%Gillespie's algorithm works by repeating the following steps, starting
%from the initial mixture:

\input{algos/gillespie.tex}
\input{algos/cosimulation.tex}


%\begin{theorem}[Corectness of resimulation]
%Let $\tau$ a trace and $\iota$ an intervention.
%We write $R_\iota(\tau)$ the random variable defined by the resimulation
%algorithm. Then, 
%${\hat T}_\iota \,|\, \{T = \tau\}$ and $R_\iota(\tau)$ have
%the same probability law.
%\end{theorem}


\subsection{Deriving the cosimulation algorithm}

Suppose you are simulating a counterfactual trace for intervention $\iota$
and reference trace $\tau$, that is, you are drawing an instance of
$\hat T_\iota \,|\, \{T=\tau\}$. Suppose you have already simulated the
first $t$ seconds of this counterfactual trace and you want to know the time
of the next event. Because both $T$, $\hat T_\iota$ and $\Sigma$ are markovian,
the only only relevant information about what has already been simulated is the
current state of the counterfactual world $s := \TSTATE{t}{\hat T_\iota}$.


If we write $\delta$ the time difference between $t$ and the next event after $t$ in $\tau$,
we are interested in the following probability:
\begin{equation}
\CProb{ \hat T_\iota \cap [t, t+\delta) = \emptyset  }
%{ \underbrace{T=\tau, M = \mathcal{S}_t(\hat T_\iota)}_{\Delta} }
{ T=\tau,\, s = \TSTATE{t}{\hat T_\iota} }
\end{equation}
Writing $I = [t, t+\delta)$, this quantity can be rewritten as follows:
\begin{align}
\ & \ \CProb{ \hat T_\iota \cap I = \emptyset }
{ T=\tau,\, s = \TSTATE{t}{\hat T_\iota} } \\[0.5em]
= & \ \CProb{ \bigwedge_{s \vdash e} (\,e \notin \Sigma \cap I \,)  }{ T=\tau } \\[1em]
= & \ \prod_{s \vdash e}\, \CProb{e \notin \Sigma \cap I }{ T=\tau }
\end{align}
Indeed, given that $s = \TSTATE{t}{\hat T_\iota}$, 
no counterfactual event happens in time interval $I$
if and only if no potential event that is triggerable from state $s$ is scheduled in $I$. 
Besides, potential events are scheduled independently and so we can
decompose the resulting probability as a product.

Let $e$ a potential event such that $s \vdash e$. The probability
that $e$ has not been scheduled in $I$ given that $T=\tau$ depends on whether or not
$e$ is triggerable from state $s_0 := \TSTATE{t}{T}$. Indeed, we assumed that
$\tau$ contains no event in time interval $I$. Therefore, if $s_0 \vdash e$, then
$e$ cannot be scheduled in $I$, without which it would have been observed in $\tau$.
Thus, \[ s_0 \vdash e \ \Rightarrow\  \CProb{e \notin \Sigma \cap I}{ T=\tau } = 1  \]
Besides, if $s_0 \not\vdash e$, then the observation $\{ T=\tau \}$ gives absolutely
no information on whether or not $e$ has been scheduled in $I$ and so
\[ s_0 \not\vdash e \ \Rightarrow\  \CProb{e \notin \Sigma \cap I}{ T=\tau } 
= e^{-\lambda_e \cdot \delta}  \]
as the scheduling process of a potential event is a Poisson process. Combining these
two results with (4), we have:
\begin{align}
\CProb{ \hat T_\iota \cap I = \emptyset }{ \Delta }
=\ \prod_{s \vdash e, \, s_0 \not\vdash e} e^{-\lambda_e} = e^{-\alpha'(s, s_0)\cdot\delta}
\end{align}
where \[\alpha'(s, s_0) := \sum_{s \vdash e, \, s_0 \not\vdash e} \lambda_e \]
This quantity can be rewritten as follows:
\begin{align}
\alpha'(s, s_0) &= 
\sum_{(r, \xi)} \textbf{1}\{ s \vdash (r, \xi),\ s_o \not\vdash (r, \xi) \}\cdot\lambda_r \\
&= \sum_r \lambda_r\sum_\xi \textbf{1}\{ s \vdash (r, \xi),\ s_o \not\vdash (r, \xi) \} \\
&= \sum_r \lambda_r |\DEMBS{r}{s, s_0}|
\end{align}
which gives us the definition of divergent activity. This result can be summarized in
the following theorem:
\begin{theorem} Let $\tau$ a trace and $\iota$ an intervention. Let $I$ a time interval
of width $\delta$ such that $\tau \cap I = \emptyset$. Then,
\[\CProb{ \hat T_\iota \cap I = \emptyset }{ T=\tau,\ \TSTATE{t}{\hat T_\iota} = s\ }
\ =\ e^{-\alpha'(s, s_0) \cdot \delta}
\]
where $s_0 = \mathcal{S}_t(\tau)$ and
\[\alpha'(s, s_0) = \sum_r \lambda_r |\DEMBS{r}{s, s_0}| \]
is the total divergent activity of $s$ with respect to $s_0$.
\end{theorem}
During normal simulation of a Kappa model, the activity of the reaction mixture can 
be interpreted as its propensity to change. In contrast, during counterfactual
simulation, the divergent activity can be interpreted as the propensity of the counterfactual
mixture to diverge from the reference mixture.






%$M_0 := \mathcal{S}_t(\hat \tau)$
%= \CProb{ \bigwedge_e (\,e \notin \hat T_\iota \cap [t, t+\delta)\,)  }{ \Delta } \\
